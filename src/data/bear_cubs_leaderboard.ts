export const bearCubsLeaderboard = [
  {
    category: "LLM baselines",
    model: "GPT-4.1",
    accuracy: {
      all: "20.1%",
      text_only: "17.6%",
      multimodal: "25.7%"
    },
    answer_label: {
      correct: "45",
      wrong: "50",
      uncertain: "5",
      none: "0"
    },
    average_time: {
      correct: "3:00",
      wrong: "4:00",
      uncertain: "2:00"
    }
  },
  {
    category: "LLM baselines",
    model: "O3-MINI",
    accuracy: {
      all: "12.0%",
      text_only: "9.5%",
      multimodal: "20.0%"
    },
    answer_label: {
      correct: "20",
      wrong: "60",
      uncertain: "20",
      none: "0"
    },
    average_time: {
      correct: "2:20",
      wrong: "3:10",
      uncertain: "1:40"
    }
  },
  {
    category: "LLM baselines",
    model: "O3",
    accuracy: {
      all: "33.7%",
      text_only: "32.4%",
      multimodal: "48.6%"
    },
    answer_label: {
      correct: "60",
      wrong: "30",
      uncertain: "10",
      none: "0"
    },
    average_time: {
      correct: "2:50",
      wrong: "3:30",
      uncertain: "1:10"
    }
  },
  {
    category: "LLM baselines",
    model: "LLAMA-4-Scout",
    accuracy: {
      all: "4.3%",
      text_only: "6.8%",
      multimodal: "8.6%"
    },
    answer_label: {
      correct: "5",
      wrong: "85",
      uncertain: "10",
      none: "0"
    },
    average_time: {
      correct: "1:15",
      wrong: "2:10",
      uncertain: "0:45"
    }
  },
  {
    category: "LLM baselines",
    model: "DeepSeek-R1",
    accuracy: {
      all: "10.3%",
      text_only: "10.8%",
      multimodal: "14.3%"
    },
    answer_label: {
      correct: "15",
      wrong: "70",
      uncertain: "15",
      none: "0"
    },
    average_time: {
      correct: "2:05",
      wrong: "3:00",
      uncertain: "2:40"
    }
  }
];
